{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed16d76e",
   "metadata": {},
   "source": [
    "# Data Cleaning for OpenFoodFacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f72c5",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b942f9",
   "metadata": {},
   "source": [
    "Dataset Description..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1563409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "#import re\n",
    "import regex as re\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc8d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "openfoodfactsUrl = path + '/data/en.openfoodfacts.org.products.2.csv'\n",
    "foodtableUrl = path + '/data/data_2.tsv'\n",
    "\n",
    "ingredients_tx = path + '/data/ingredients.txt'\n",
    "packaging_materials_tx = path + '/data/packaging_materials.txt'\n",
    "packaging_shapes_tx = path + '/data/packaging_shapes.txt'\n",
    "\n",
    "savePath =  path + '/data/foodDB/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b71dd",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863ffef",
   "metadata": {},
   "source": [
    "Helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dataset\n",
    "\n",
    "def plotMissingValues(dataframe, width, high, character=False):\n",
    "    plt.figure(figsize=(width, high)) \n",
    "    if character==False:\n",
    "        ax = dataframe.isnull().sum().plot.barh(color='skyblue') \n",
    "    else:\n",
    "        occurrences = (dataframe == character).sum().sort_values(ascending=True)\n",
    "        ax = occurrences.plot.barh(color='skyblue') \n",
    "\n",
    "\n",
    "    # Customizing the plot\n",
    "\n",
    "    plt.title('Missing Values per Column', fontsize=16)\n",
    "    plt.xlabel('Number of Missing Values', fontsize=12)\n",
    "    plt.ylabel('Columns', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7) \n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "\n",
    "\n",
    "    # Display the values on the bars\n",
    "    \n",
    "    if character==False:\n",
    "        for i, v in enumerate(dataframe.isnull().sum()):\n",
    "            ax.text(v + 500, i, str(v), color='gray', va='center', fontsize=8)\n",
    "    else:\n",
    "        for i, v in enumerate(occurrences):\n",
    "            ax.text(v + 500, i, str(v), color='gray', va='center', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec0418",
   "metadata": {},
   "source": [
    "## Import Data (Chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc67cc8",
   "metadata": {},
   "source": [
    "Load the data (one chunk) from a .tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea68a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "chunk_size = 100000\n",
    "chunks_df = pd.read_csv(openfoodfactsUrl, sep=\"\\t\", chunksize=chunk_size)\n",
    "\n",
    "for chunk_df in chunks_df:\n",
    "    print(chunk_df.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58bd2b",
   "metadata": {},
   "source": [
    "## Data Exploration (Chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a575604",
   "metadata": {},
   "source": [
    "Data Exploration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View columns name\n",
    "\n",
    "print(chunk_df.columns.values)\n",
    "\n",
    "chunk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dataset\n",
    "    \n",
    "plotMissingValues(chunk_df, 7, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b085503",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed53dbc",
   "metadata": {},
   "source": [
    "Load the data from a .tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beef33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the filter\n",
    "# $ = keep as is | - = don't keep | ? - keep as optional | t = translate\n",
    "\n",
    "df_filter = [\"code\", #$$$$$$\n",
    "             \"product_name\", #$$$$$$\n",
    "             \"packaging_tags\", #?t?t?t (enumerate)\n",
    "             \"brands\", #??????\n",
    "             \"brands_tags\", #??????\n",
    "             \"labels_en\", #t?t?t? (da processare)\n",
    "             \"countries_en\", #$$$$$$ (importare il dataset poi - o countries-tags)\n",
    "             \"ingredients_tags\", #$t$t$t (tassonomia - o ingredients_text o ingredients_analysis_tags)\n",
    "             \"serving_size\", #??????\n",
    "             \"additives_n\", #------ Usato solo per processare additives_tags\n",
    "             \"additives_tags\", #?????? (importare il dataset poi)\n",
    "             \"nutriscore_score\", #??????\n",
    "             \"nutriscore_grade\", #??????\n",
    "             \"nova_group\", #??????\n",
    "             \"food_groups\", #??????\n",
    "             \"food_groups_tags\", #?????? (o food_groups_en)\n",
    "             \"brand_owner\", #??????\n",
    "             \"ecoscore_grade\", #??????\n",
    "             #\"main_category_en\", #------ (sostituito da food_groups_en)\n",
    "             \"energy-kcal_100g\", #$$$$$$\n",
    "             \"energy_100g\", #$$$$$$\n",
    "             \"fat_100g\", #$$$$$$$\n",
    "             \"saturated-fat_100g\", #??????\n",
    "             \"trans-fat_100g\", #??????\n",
    "             \"cholesterol_100g\", #??????\n",
    "             \"carbohydrates_100g\", #$$$$$$\n",
    "             \"sugars_100g\", #??????\n",
    "             \"fiber_100g\", #??????\n",
    "             \"proteins_100g\", #$$$$$$\n",
    "             \"salt_100g\", #??????\n",
    "             \"sodium_100g\", #??????\n",
    "             \"vitamin-a_100g\", #??????\n",
    "             \"vitamin-c_100g\", #??????\n",
    "             \"calcium_100g\", #??????\n",
    "             \"iron_100g\"] #??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a91f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = pd.read_csv(openfoodfactsUrl, sep=\"\\t\", usecols=df_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858eb57d",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef7bd0",
   "metadata": {},
   "source": [
    "Data Exploration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View columns name\n",
    "\n",
    "print(filter_df.columns.values)\n",
    "\n",
    "filter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dataset\n",
    "    \n",
    "plotMissingValues(filter_df, 7, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c16f2",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9a912",
   "metadata": {},
   "source": [
    "Data Cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values in additives_tags with empty string if additives_n is 0\n",
    "\n",
    "def replace_null(row):\n",
    "    if row['additives_n'] == 0 and pd.isnull(row['additives_tags']):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return row['additives_tags']\n",
    "    \n",
    "def replace_null_bycoll(row, col):\n",
    "    if pd.isnull(row[col]):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return row[col]\n",
    "    \n",
    "\n",
    "filter_df['additives_tags'] = filter_df.apply(replace_null, axis=1)\n",
    "\n",
    "filter_df[\"packaging_tags\"] = filter_df.apply(replace_null_bycoll, args=('packaging_tags',), axis=1)\n",
    "filter_df[\"brands\"] = filter_df.apply(replace_null_bycoll, args=('brands',), axis=1)\n",
    "filter_df[\"brands_tags\"] = filter_df.apply(replace_null_bycoll, args=('brands_tags',), axis=1)\n",
    "filter_df[\"labels_en\"] = filter_df.apply(replace_null_bycoll, args=('labels_en',), axis=1)\n",
    "filter_df[\"serving_size\"] = filter_df.apply(replace_null_bycoll, args=('serving_size',), axis=1)\n",
    "filter_df[\"nutriscore_score\"] = filter_df.apply(replace_null_bycoll, args=('nutriscore_score',), axis=1)\n",
    "filter_df[\"nutriscore_grade\"] = filter_df.apply(replace_null_bycoll, args=('nutriscore_grade',), axis=1)\n",
    "filter_df[\"nova_group\"] = filter_df.apply(replace_null_bycoll, args=('nova_group',), axis=1)\n",
    "filter_df[\"food_groups\"] = filter_df.apply(replace_null_bycoll, args=('food_groups',), axis=1)\n",
    "filter_df[\"food_groups_tags\"] = filter_df.apply(replace_null_bycoll, args=('food_groups_tags',), axis=1)\n",
    "#filter_df[\"food_groups_en\"] = filter_df.apply(replace_null_bycoll, args=('food_groups_en',), axis=1)\n",
    "filter_df[\"brand_owner\"] = filter_df.apply(replace_null_bycoll, args=('brand_owner',), axis=1)\n",
    "filter_df[\"ecoscore_grade\"] = filter_df.apply(replace_null_bycoll, args=('ecoscore_grade',), axis=1)\n",
    "#filter_df[\"main_category_en\"] = filter_df.apply(replace_null_bycoll, args=('main_category_en',), axis=1)\n",
    "filter_df[\"saturated-fat_100g\"] = filter_df.apply(replace_null_bycoll, args=('saturated-fat_100g',), axis=1)\n",
    "filter_df[\"trans-fat_100g\"] = filter_df.apply(replace_null_bycoll, args=('trans-fat_100g',), axis=1)\n",
    "filter_df[\"cholesterol_100g\"] = filter_df.apply(replace_null_bycoll, args=('cholesterol_100g',), axis=1)\n",
    "filter_df[\"sugars_100g\"] = filter_df.apply(replace_null_bycoll, args=('sugars_100g',), axis=1)\n",
    "filter_df[\"fiber_100g\"] = filter_df.apply(replace_null_bycoll, args=('fiber_100g',), axis=1)\n",
    "filter_df[\"salt_100g\"] = filter_df.apply(replace_null_bycoll, args=('salt_100g',), axis=1)\n",
    "filter_df[\"sodium_100g\"] = filter_df.apply(replace_null_bycoll, args=('sodium_100g',), axis=1)\n",
    "filter_df[\"vitamin-a_100g\"] = filter_df.apply(replace_null_bycoll, args=('vitamin-a_100g',), axis=1)\n",
    "filter_df[\"vitamin-c_100g\"] = filter_df.apply(replace_null_bycoll, args=('vitamin-c_100g',), axis=1)\n",
    "filter_df[\"calcium_100g\"] = filter_df.apply(replace_null_bycoll, args=('calcium_100g',), axis=1)\n",
    "filter_df[\"iron_100g\"] = filter_df.apply(replace_null_bycoll, args=('iron_100g',), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter to the Dataframe\n",
    "\n",
    "food_table = filter_df[df_filter].copy()\n",
    "\n",
    "food_table[\"isempty\"] = np.where(food_table.isnull().sum(axis=1) >= 1, 1, 0)\n",
    "percentage = food_table.isempty.value_counts()[1] / food_table.shape[0] * 100\n",
    "print(\"Percentage of dropped rows: \" + str(percentage))\n",
    "\n",
    "food_table = food_table[food_table.isempty==0].copy()\n",
    "food_table.isnull().sum()\n",
    "\n",
    "food_table.drop(\"isempty\", inplace=True,axis=1)\n",
    "food_table.dropna(axis = 0, how = \"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ea1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dataset\n",
    "    \n",
    "plotMissingValues(food_table, 7, 6, character=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329e4ba0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>product_name</th>\n",
       "      <th>packaging_tags</th>\n",
       "      <th>brands</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>labels_en</th>\n",
       "      <th>countries_en</th>\n",
       "      <th>ingredients_tags</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>additives_n</th>\n",
       "      <th>additives_tags</th>\n",
       "      <th>nutriscore_score</th>\n",
       "      <th>nutriscore_grade</th>\n",
       "      <th>nova_group</th>\n",
       "      <th>food_groups</th>\n",
       "      <th>food_groups_tags</th>\n",
       "      <th>brand_owner</th>\n",
       "      <th>ecoscore_grade</th>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199</td>\n",
       "      <td>Solène céréales poulet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CROUS</td>\n",
       "      <td>crous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>en:antioxidant,en:colour,en:tomato,en:vegetabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en:e150,en:e160a,en:e202,en:e316,en:e466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1663</td>\n",
       "      <td>Crème dessert chocolat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ferme De La Frémondière</td>\n",
       "      <td>ferme-de-la-fremondiere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>en:whole-milk,en:dairy,en:milk,en:sugar,en:add...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en:e406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2264</td>\n",
       "      <td>Baguette Poitevin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crous resto</td>\n",
       "      <td>crous-resto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>fr:baguette-poite-vin-pain-baguette,en:water,e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3827</td>\n",
       "      <td>Suedois saumon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crous</td>\n",
       "      <td>crous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>fr:paln-suedois,en:water,en:rye-flour,en:flour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>en:e300,en:e503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.580</td>\n",
       "      <td>1.4320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4510</td>\n",
       "      <td>Salade shaker taboulé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crous</td>\n",
       "      <td>crous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>fr:taboule,en:vegetable,en:colza-oil,en:oil-an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en:e202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code            product_name packaging_tags                   brands  \\\n",
       "0  1199  Solène céréales poulet            NaN                    CROUS   \n",
       "1  1663  Crème dessert chocolat            NaN  Ferme De La Frémondière   \n",
       "2  2264       Baguette Poitevin            NaN              Crous resto   \n",
       "3  3827          Suedois saumon            NaN                    Crous   \n",
       "4  4510   Salade shaker taboulé            NaN                    Crous   \n",
       "\n",
       "               brands_tags labels_en countries_en  \\\n",
       "0                    crous       NaN       France   \n",
       "1  ferme-de-la-fremondiere       NaN       France   \n",
       "2              crous-resto       NaN       France   \n",
       "3                    crous       NaN       France   \n",
       "4                    crous       NaN       France   \n",
       "\n",
       "                                    ingredients_tags serving_size  \\\n",
       "0  en:antioxidant,en:colour,en:tomato,en:vegetabl...          NaN   \n",
       "1  en:whole-milk,en:dairy,en:milk,en:sugar,en:add...          NaN   \n",
       "2  fr:baguette-poite-vin-pain-baguette,en:water,e...          NaN   \n",
       "3  fr:paln-suedois,en:water,en:rye-flour,en:flour...          NaN   \n",
       "4  fr:taboule,en:vegetable,en:colza-oil,en:oil-an...          NaN   \n",
       "\n",
       "   additives_n                            additives_tags  nutriscore_score  \\\n",
       "0          5.0  en:e150,en:e160a,en:e202,en:e316,en:e466               NaN   \n",
       "1          1.0                                   en:e406               NaN   \n",
       "2          0.0                                       NaN               NaN   \n",
       "3          2.0                           en:e300,en:e503               NaN   \n",
       "4          1.0                                   en:e202               NaN   \n",
       "\n",
       "  nutriscore_grade  nova_group food_groups food_groups_tags brand_owner  \\\n",
       "0              NaN         4.0         NaN              NaN         NaN   \n",
       "1              NaN         4.0         NaN              NaN         NaN   \n",
       "2              NaN         4.0         NaN              NaN         NaN   \n",
       "3              NaN         4.0         NaN              NaN         NaN   \n",
       "4              NaN         4.0         NaN              NaN         NaN   \n",
       "\n",
       "  ecoscore_grade  energy-kcal_100g  energy_100g  fat_100g  saturated-fat_100g  \\\n",
       "0            NaN             219.0        916.0       5.9                 0.5   \n",
       "1            NaN               0.0          0.0       0.0                 0.0   \n",
       "2            NaN             207.0        866.0       6.7                 3.8   \n",
       "3            NaN             172.0        720.0       4.4                 1.2   \n",
       "4            NaN             114.0        477.0       8.1                 0.9   \n",
       "\n",
       "   trans-fat_100g  cholesterol_100g  carbohydrates_100g  sugars_100g  \\\n",
       "0             NaN               NaN                30.3          1.7   \n",
       "1             NaN               NaN                 0.0          0.0   \n",
       "2             NaN               NaN                27.5          0.6   \n",
       "3             NaN               NaN                23.3          4.6   \n",
       "4             NaN               NaN                 5.7          1.4   \n",
       "\n",
       "   fiber_100g  proteins_100g  salt_100g  sodium_100g  vitamin-a_100g  \\\n",
       "0         2.8            9.7      0.464       0.1856             NaN   \n",
       "1         NaN            0.0      0.000       0.0000             NaN   \n",
       "2         1.7            8.9      0.400       0.1600             NaN   \n",
       "3         2.7            8.4      3.580       1.4320             NaN   \n",
       "4         1.7            3.9      0.310       0.1240             NaN   \n",
       "\n",
       "   vitamin-c_100g  calcium_100g  iron_100g  \n",
       "0             NaN           NaN        NaN  \n",
       "1             NaN           NaN        NaN  \n",
       "2             NaN           NaN        NaN  \n",
       "3             NaN           NaN        NaN  \n",
       "4             NaN           NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "food_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3c5a0",
   "metadata": {},
   "source": [
    "## Save or Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new Dataset\n",
    "\n",
    "food_table.to_csv(path + '/data/data_2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44296a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitto\\AppData\\Local\\Temp\\ipykernel_16408\\2897025573.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  food_table = pd.read_csv(foodtableUrl, sep=\"\\t\", na_values='unknown')\n"
     ]
    }
   ],
   "source": [
    "# Import the Dataset\n",
    "\n",
    "#food_table = pd.read_csv(foodtableUrl, sep=\"\\t\", na_values=['unknown'], keep_default_na=False)\n",
    "food_table = pd.read_csv(foodtableUrl, sep=\"\\t\", na_values='unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd9c7d",
   "metadata": {},
   "source": [
    "## Ingredients Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_map = {}\n",
    "\n",
    "def cl_ingredients(text, ingredients_map, debug = False):\n",
    "    \n",
    "\n",
    "    # Pattern to split the text\n",
    "    \n",
    "    # pattern = r\"[,.()\\[\\]{}]\"\n",
    "    pattern = r\"[,]\"\n",
    "    split_text = re.split(pattern, text)\n",
    "\n",
    "    for ingredient in split_text:\n",
    "        if ingredient in ingredients_map:\n",
    "            ingredients_map[ingredient] += 1\n",
    "        else:\n",
    "            ingredients_map[ingredient] = 1\n",
    "    \n",
    "   \n",
    "    if debug:\n",
    "        print(text)\n",
    "#        print(text)\n",
    "        \n",
    "    #return ', '.join(result)\n",
    "\n",
    "#cl_ingredients(food_table.at[32, 'ingredients_tags'], ingredients_map, False)\n",
    "food_table['ingredients_tags'].apply(cl_ingredients, args=(ingredients_map,))\n",
    "print(len(ingredients_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to save the CSV data\n",
    "file_path = path + '/data/ingrediets_2.tsv'\n",
    "\n",
    "sorted_ingredients = dict(sorted(ingredients_map.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Writing the dictionary to a CSV file with tab-separated values\n",
    "with open(file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter='\\t')\n",
    "    writer.writerow(['Ingredient', 'Count'])  # Writing header\n",
    "    for ingredient, count in sorted_ingredients.items():\n",
    "        writer.writerow([ingredient, count])\n",
    "\n",
    "print(f\"Dictionary has been written to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014539b1",
   "metadata": {},
   "source": [
    "## Read Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line(text):\n",
    "    \n",
    "    split_text = re.split(':', text)\n",
    "    \n",
    "    language_tag = split_text[0]\n",
    "    ingredients_text = split_text[1]\n",
    "    \n",
    "    ingredients = re.split(', ', ingredients_text)\n",
    "    stripped_ingredients = [ingredient.strip() for ingredient in ingredients]\n",
    "    \n",
    "    return language_tag, stripped_ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98efc228",
   "metadata": {},
   "source": [
    "Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the taxonomy line by line and add each element to a dictionary\n",
    "\n",
    "ingredients_tx_map = {}\n",
    "master = ''\n",
    "master_tag = ''\n",
    "start = True\n",
    "count_masters = 0\n",
    "\n",
    "\n",
    "with open(ingredients_tx, 'r', encoding='utf-8') as file:\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "        # Iterate until ingredients\n",
    "        if start and '# # # # # # # # # # # # # #' not in line:\n",
    "            continue\n",
    "        else:\n",
    "            start = False\n",
    "            \n",
    "        # Check if there is a new section\n",
    "        if line == '\\n':\n",
    "            master = ''\n",
    "            #print('reset')\n",
    "            \n",
    "        # Skip the line if is a comment or if is not a valid line\n",
    "        if '#' in line or line.count(':') != 1 or '<' in line:\n",
    "            continue\n",
    "        \n",
    "        language_tag, ingredients = split_line(line)\n",
    "        \n",
    "        # Add the line to the dictionary\n",
    "        if language_tag == 'en' or master == '':\n",
    "            master = ingredients[0]\n",
    "            master_tag = language_tag\n",
    "            count_masters += 1\n",
    "        \n",
    "        for ingredient in ingredients:\n",
    "            ingredient = ingredient\n",
    "            ingredients_tx_map[language_tag+':'+ingredient] = master_tag+':'+master\n",
    "        \n",
    "        \n",
    "    print('# of elements in the dictionary: ' + str(len(ingredients_tx_map)))\n",
    "    print('# of master elements in the dictionary: ' + str(count_masters) + '\\n')\n",
    "    print(ingredients_tx_map)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa10517d",
   "metadata": {},
   "source": [
    "Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the taxonomy line by line and add each element to a dictionary\n",
    "\n",
    "packaging_tx_map = {}\n",
    "master = ''\n",
    "master_tag = ''\n",
    "start = True\n",
    "count_masters = 0\n",
    "\n",
    "\n",
    "with open(packaging_materials_tx, 'r', encoding='utf-8') as file:\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "        # Iterate until ingredients (deactivated)\n",
    "        if start and 'en:Plastic' not in line:\n",
    "            continue\n",
    "        else:\n",
    "            start = False\n",
    "            \n",
    "        # Check if there is a new section\n",
    "        if line == '\\n':\n",
    "            master = ''\n",
    "            #print('reset')\n",
    "            \n",
    "        # Skip the line if is a comment or if is not a valid line\n",
    "        if '#' in line or line.count(':') != 1 or '<' in line:\n",
    "            continue\n",
    "        \n",
    "        line = line.lower() #IMPORTANT\n",
    "        language_tag, ingredients = split_line(line)\n",
    "        \n",
    "        # Add the line to the dictionary\n",
    "        if language_tag == 'en' or master == '':\n",
    "            master = ingredients[0]\n",
    "            master_tag = language_tag\n",
    "            count_masters += 1\n",
    "        \n",
    "        for ingredient in ingredients:\n",
    "            ingredient = ingredient\n",
    "            packaging_tx_map[language_tag+':'+ingredient] = master_tag+':'+master\n",
    "        \n",
    "        \n",
    "    print('# of elements in the dictionary: ' + str(len(packaging_tx_map)))\n",
    "    print('# of master elements in the dictionary: ' + str(count_masters) + '\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "master = ''\n",
    "master_tag = ''\n",
    "start = True        \n",
    "        \n",
    "with open(packaging_shapes_tx, 'r', encoding='utf-8') as file:\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "        # Iterate until ingredients (deactivated)\n",
    "        if start and 'en:packaging' not in line:\n",
    "            continue\n",
    "        else:\n",
    "            start = False\n",
    "            \n",
    "        # Check if there is a new section\n",
    "        if line == '\\n':\n",
    "            master = ''\n",
    "            #print('reset')\n",
    "            \n",
    "        # Skip the line if is a comment or if is not a valid line\n",
    "        if '#' in line or line.count(':') != 1 or '<' in line:\n",
    "            continue\n",
    "        \n",
    "        line = line.lower() # IMPORTANT\n",
    "        language_tag, ingredients = split_line(line)\n",
    "        \n",
    "        # Add the line to the dictionary\n",
    "        if language_tag == 'en' or master == '':\n",
    "            master = ingredients[0]\n",
    "            master_tag = language_tag\n",
    "            count_masters += 1\n",
    "        \n",
    "        for ingredient in ingredients:\n",
    "            ingredient = ingredient\n",
    "            packaging_tx_map[language_tag+':'+ingredient] = master_tag+':'+master\n",
    "        \n",
    "        \n",
    "    print('# of elements in the dictionary: ' + str(len(packaging_tx_map)))\n",
    "    print('# of master elements in the dictionary: ' + str(count_masters) + '\\n')\n",
    "    print(packaging_tx_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc784b7b",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b77a1",
   "metadata": {},
   "source": [
    "Data Visualization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the entries in a DataFrame's target column based on a specified separator, \n",
    "# creating new rows for each element resulting from the split.\n",
    "\n",
    "def splitDataFrameList(df, target_column, separator):\n",
    "    def splitListToRows(row, row_accumulator, target_column, separator):\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args = (new_rows,target_column,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad15021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print original dataset\n",
    "\n",
    "countries = df[\"countries_en\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aaf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the horizontal bar chart\n",
    "\n",
    "ax = countries[:15][::-1].plot.barh(figsize=(8, 4), color='skyblue')\n",
    "plt.xlabel('Values')\n",
    "plt.title('Top 15 Countries')\n",
    "\n",
    "\n",
    "# Displaying the value of each bar on the plot\n",
    "\n",
    "for i, v in enumerate(countries[:15][::-1]):\n",
    "    ax.text(v + 500, i, str(v), color='black', va='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efdbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print new dataset\n",
    "\n",
    "food_countries = splitDataFrameList(food_table, \"countries_en\", \",\")\n",
    "countries = food_countries[\"countries_en\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6515140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the horizontal bar chart\n",
    "\n",
    "ax = countries[:15][::-1].plot.barh(figsize=(8, 4), color='skyblue')\n",
    "plt.xlabel('Values')\n",
    "plt.title('Top 15 Countries')\n",
    "\n",
    "\n",
    "# Displaying the value of each bar on the plot\n",
    "\n",
    "for i, v in enumerate(countries[:15][::-1]):\n",
    "    ax.text(v + 500, i, str(v), color='black', va='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110570d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print new dataset\n",
    "\n",
    "food_countries = splitDataFrameList(food_table, \"ingredients_tags\", \",\")\n",
    "countries = food_countries[\"ingredients_tags\"].str.split(',').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec004d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the horizontal bar chart\n",
    "\n",
    "ax = countries[:15][::-1].plot.barh(figsize=(8, 4), color='skyblue')\n",
    "plt.xlabel('Values')\n",
    "plt.title('Top 15 Countries')\n",
    "\n",
    "\n",
    "# Displaying the value of each bar on the plot\n",
    "\n",
    "for i, v in enumerate(countries[:15][::-1]):\n",
    "    ax.text(v + 500, i, str(v), color='black', va='center', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b74827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4bb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.to_csv(path + '/data/ingredients.tsv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04725746",
   "metadata": {},
   "source": [
    "## Populate DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the movie ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "FO = Namespace(\"http://www.graphle.com/foodOntology#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_first_letters(text):\n",
    "    return ' '.join(str(text).split('-')).title()\n",
    "\n",
    "def remove_language_tag(text):\n",
    "    split_text = re.split(':', str(text))\n",
    "    \n",
    "    if len(split_text) > 1:\n",
    "        return split_text[1]\n",
    "    print(\"No language tag in \" + str(text))\n",
    "    return split_text[0]\n",
    "\n",
    "def create_tag(text):\n",
    "    lower = str(text).lower().strip()\n",
    "    cleared = re.sub(r'[^\\p{L}\\d\\s-]', \"\", lower, flags=re.UNICODE)\n",
    "    return '-'.join(cleared.split())\n",
    "\n",
    "def split_tags(text):\n",
    "    return str(text).split(',')\n",
    "\n",
    "def filter_tags(text, dictionary):\n",
    "    result = []\n",
    "    if pd.isna(text):\n",
    "        return result\n",
    "    \n",
    "    splitted = split_tags(text)\n",
    "    \n",
    "    for item in splitted:\n",
    "        if item in dictionary:\n",
    "            result.append(dictionary[item])\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc42961",
   "metadata": {},
   "source": [
    "### Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over the league dataframe\n",
    "for index, row in food_table.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the league id as URI\n",
    "    idU = create_tag(row['brands_tags'])\n",
    "    \n",
    "    \n",
    "    if not pd.isna(idU) and not idU == '':\n",
    "        Brand = URIRef(FO[idU])\n",
    "        # Add triples using store's add() method.\n",
    "        if not (Brand, None, None) in g:   \n",
    "            g.add((Brand, RDF.type, FO.Brand))\n",
    "            if not pd.isna(row['brands']):\n",
    "                g.add((Brand, FO['name'], Literal(capitalize_first_letters(row['brands']), datatype=XSD.string)))  \n",
    "            else:\n",
    "                g.add((Brand, FO['name'], Literal(capitalize_first_letters(row['brands_tags']), datatype=XSD.string)))\n",
    "            if not pd.isna(row['brand_owner']):\n",
    "                g.add((Brand, FO['owner'], Literal(row['brand_owner'], datatype=XSD.string)))\n",
    "    \n",
    "    \n",
    "    if index % 150000 == 0 :\n",
    "        print(f\"Progress: {index/food_table.shape[0]*100:.2f}%\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    #if index == 100:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'brand.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2370e6f",
   "metadata": {},
   "source": [
    "### FoodGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affef3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c3d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterate over the league dataframe\n",
    "for index, row in food_table.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the league id as URI\n",
    "    idU = row['food_groups']\n",
    "    if not pd.isna(idU):\n",
    "        \n",
    "        idU = remove_language_tag(row['food_groups'])\n",
    "        FoodGroup = URIRef(FO[idU])\n",
    "        # Add triples using store's add() method.\n",
    "        if not (FoodGroup, None, None) in g:   \n",
    "            g.add((FoodGroup, RDF.type, FO.FoodGroup))\n",
    "            g.add((FoodGroup, FO['name'], Literal(capitalize_first_letters(idU), datatype=XSD.string)))  \n",
    "    \n",
    "    \n",
    "    if index % 150000 == 0 :\n",
    "        print(f\"Progress: {index/food_table.shape[0]*100:.2f}%\")\n",
    "        \n",
    "    # C'E' UN UNKNOWN\n",
    "    \n",
    "    \n",
    "    #if index == 100:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aaf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'foodgroups.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d5def",
   "metadata": {},
   "source": [
    "### Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over the league dataframe\n",
    "for index, row in food_table.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the league id as URI\n",
    "    idU = create_tag(row['product_name']) + '-' + str(row['code'])\n",
    "    \n",
    "    if idU.startswith('-'):\n",
    "        continue\n",
    "    \n",
    "    Product = URIRef(FO[idU])\n",
    "    \n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Product, RDF.type, FO.Product))\n",
    "    g.add((Product, FO['name'], Literal(row['product_name'], datatype=XSD.string)))  \n",
    "    if not pd.isna(row['serving_size']):\n",
    "        g.add((Product, FO['servingSize'], Literal(row['serving_size'], datatype=XSD.string)))\n",
    "    if not pd.isna(row['nutriscore_score']):\n",
    "        g.add((Product, FO['nutriscoreScore'], Literal(row['nutriscore_score'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['nutriscore_grade']):\n",
    "        g.add((Product, FO['nutriscoreGrade'], Literal(row['nutriscore_grade'], datatype=XSD.string)))\n",
    "    if not pd.isna(row['nova_group']):\n",
    "        g.add((Product, FO['novaGroup'], Literal(row['nova_group'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['nova_group']):\n",
    "        g.add((Product, FO['ecoscoreGrade'], Literal(row['ecoscore_grade'], datatype=XSD.string)))   \n",
    "    g.add((Product, FO['energyKJ'], Literal(row['energy_100g'], datatype=XSD.float)))\n",
    "    g.add((Product, FO['energyKcal'], Literal(row['energy-kcal_100g'], datatype=XSD.float)))\n",
    "    g.add((Product, FO['fat'], Literal(row['fat_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['saturated-fat_100g']):\n",
    "        g.add((Product, FO['fatSaturated'], Literal(row['saturated-fat_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['trans-fat_100g']):\n",
    "        g.add((Product, FO['fatTrans'], Literal(row['trans-fat_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['cholesterol_100g']):    \n",
    "        g.add((Product, FO['cholesterol'], Literal(row['cholesterol_100g'], datatype=XSD.float)))\n",
    "    g.add((Product, FO['carbohydrates'], Literal(row['carbohydrates_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['sugars_100g']):\n",
    "        g.add((Product, FO['sugars'], Literal(row['sugars_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['fiber_100g']):\n",
    "        g.add((Product, FO['fiber'], Literal(row['fiber_100g'], datatype=XSD.float)))\n",
    "    g.add((Product, FO['proteins'], Literal(row['proteins_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['salt_100g']):\n",
    "        g.add((Product, FO['salt'], Literal(row['salt_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['sodium_100g']):\n",
    "        g.add((Product, FO['sodium'], Literal(row['sodium_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['vitamin-a_100g']):    \n",
    "        g.add((Product, FO['vitaminA'], Literal(row['vitamin-a_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['vitamin-c_100g']):\n",
    "        g.add((Product, FO['vitaminC'], Literal(row['vitamin-c_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['calcium_100g']):\n",
    "        g.add((Product, FO['calcium'], Literal(row['calcium_100g'], datatype=XSD.float)))\n",
    "    if not pd.isna(row['iron_100g']):\n",
    "        g.add((Product, FO['irom'], Literal(row['iron_100g'], datatype=XSD.float)))\n",
    "    \n",
    "    # CI SONO DEGLI UNKNOWN\n",
    "    \n",
    "    if index % 25000 == 0 :\n",
    "        print(f\"Progress: {index/food_table.shape[0]*100:.2f}%\")\n",
    "        \n",
    "    if index == 100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'product.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15895e",
   "metadata": {},
   "source": [
    "### Product Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over the league dataframe\n",
    "for index, row in food_table.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the league id as URI\n",
    "    idPr = create_tag(row['product_name']) + '-' + str(row['code'])\n",
    "    idBr = create_tag(row['brands_tags'])\n",
    "    idFG = row['food_groups']\n",
    "    \n",
    "    if idPr.startswith('-'):\n",
    "        continue\n",
    "    Product = URIRef(FO[idPr])\n",
    "    \n",
    "    # Join with Brand\n",
    "    if not pd.isna(idBr) and not idBr == '':\n",
    "        \n",
    "        Brand = URIRef(FO[idBr])\n",
    "        \n",
    "        g.add((Product, FO['hasBrand'], Brand))\n",
    "\n",
    "    # Join with FoodGroup\n",
    "    if not pd.isna(idFG):\n",
    "        \n",
    "        idFG = remove_language_tag(row['food_groups'])\n",
    "        FoodGroup = URIRef(FO[idFG])\n",
    "        \n",
    "        g.add((Product, FO['belongsToGroup'], FoodGroup))\n",
    "        \n",
    "    # Join with Ingredient\n",
    "    ing_filtered = filter_tags(row['ingredients_tags'], ingredients_tx_map)\n",
    "    for ingredient in ing_filtered:\n",
    "        \n",
    "        idIn = 'ingredient' + str(index) # PLACEHOLDER INGREDIENT TAG\n",
    "        Ingredient = URIRef(FO[idIn])\n",
    "        \n",
    "        g.add((Product, FO['hasIngredient'], Ingredient))\n",
    "        \n",
    "    # Join with Ingredient\n",
    "    pack_filtered = filter_tags(row['packaging_tags'], packaging_tx_map)\n",
    "    for package in pack_filtered:\n",
    "        \n",
    "        idPa = 'package' + str(index) # PLACEHOLDER INGREDIENT TAG\n",
    "        Packaging = URIRef(FO[idPa])\n",
    "        \n",
    "        g.add((Product, FO['hasPackaging'], Packaging))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if index % 25000 == 0 :\n",
    "        print(f\"Progress: {index/food_table.shape[0]*100:.2f}%\")\n",
    "        \n",
    "    if index == 100000: #100000\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'product_join.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ba5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
